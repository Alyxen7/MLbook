\section{Композиции классификаторов}

В задачах классификации, регрессии и прогнозирования нередки ситуации,    когда ни один алгоритм не обеспечивает нужного качества исходной модели.  В таких случаях на помощь приходит метод композиции классификаторов, также известный как ансамблевые методы, который сочетает несколько моделей для улучшения точности и устойчивости предсказаний по сравнению с использованием одиночного классификатора. Идея применения метода зключается в том, что объединение различных алгоритмов, каждый из которых может иметь свои сильные и слабые стороны, позволяет компенсировать недостатки отдельных моделей и достигать лучших результатов.

\subsection{Основные понятия}

\begin{itemize}
    \item $X^{l \cdot n} = (x_1, ... , x_\textit{l})$ --- обучающая выборка; $Y^\textit{l} = (y_1, ... , y_\textit{l})$ - вектор ответов;
\item $a_t: X \to Y, \ t = 1, \dots, T$ --- обучаемые алгоритмы $a_t: X \to Y$, аппроксимирующие неизвестную целевую зависимость $y_i = y^*(x_i)$.
\end{itemize}
   \textbf{Идея ансамблирования} (И.Ю.Журавлев): как из множества по отдельности плохих алгоритмов \textit{$ a_t(x) $} сделать один хороший?\\ 
   \\ 
   \textbf{Понятие композиции базовых алгоритмов}  
   
   Любой базовый алгоритм представим в следующем виде: $ a_t(x) = C(b_t(x))$ 
   
   $a_t(x): \textit{X}  \overset{b_t}{\longrightarrow} \textit{R} \overset{C}{\longrightarrow} \textit{Y}$, где \textit{C} --- решающее правило, \textit{R} --- удобное пространство оценок, $b_t$ - алгоритмические операторы.

    Основная идея ансамблирования заключается в декомпозиции базового алгоритма: создании \textbf{ансамбля} \textit{агрегирующей операции F }, которая комбинирует результаты нескольких базовых алгоритмов для повышения точности предсказаний перед использованием решающего правила: 

\ \
    
    $F: \mathbb{R}^T \to \mathbb{R}$ – агрегирующая операция базовых алгоритмов $a_1, \dots, a_T$

    $$a(x) = C(F(b_1(x), \dots, b_T(x)))$$

    
Суперпозиции вида $F(b_1, ... , b_T )$ являются отображениями из X в $\mathbb{R}$, то есть, опять-таки, алгоритмическими операторами. Это позволяет строить иерархические композиции, применяя определение ансамбля рекурсивно.
Ранее не существовало четкого разделения алгоритма на две составляющие. Выбор функции ансамблирования позволяет  агрегировать результат нескольких моделей для повышения итоговой точности предсказаний.

\ \
\begin{itemize}
    \item \textbf{Пример 1:} Классификация, $Y$ – конечное множество.
    
    В этом случае $R = Y$, а $C(b) \equiv b$ – решающее правило не используется.
    \item \textbf{Пример 2:} Классификация на 2 класса, $Y = \{-1, +1\}$, алгоритм имеет вид:
    $$a(x) = \text{sign}(b(x)),$$
    В этом случае алгоритмические операторы называют также вещественнозначными классификаторами \textit{(real-valued classifiers)}: $R = \mathbb{R}$, $b: X \to \mathbb{R}$, $C(b) \equiv \text{sign}(b)$
\end{itemize}

\subsection{Агрегирующие функции}
Агрегирующая функция должна удовлетворять ряду требованиям для обеспечения эффективного комбинирования предсказаний отдельных моделей. Перечислим их:
\begin{itemize}
    \item $F(b_1, \dots, b_T) \in [\min_t b_t, \max_t b_t]$ – среднее по Коши $\forall x$;
    \item $F(b_1, \dots, b_T)$ монотонно не убывает по всем $b_t$;
    \item \textbf{Интерпретируемость}: позволяла понять, как и почему принимается то или иное решение;
    \item  \textbf{Согласованность}: она должна обеспечивать согласованность результатов, т.е. предсказания ансамбля должны быть устойчивыми при малых изменениях в данных или в отдельных моделях.
\end{itemize}

\subsubsection*{Примеры агрегирующих функций:}
\begin{itemize}
    \item \textbf{Простое голосование} (\textit{simple voting}):
    $$F(b_1, \dots , b_T) = \frac{1}{T} \sum_{t=1}^T b_t$$
    \item \textbf{Взвешенное голосование} (\textit{weighted voting}):
    $$F(b_1, \dots, b_T) = \sum_{t=1}^T \alpha_t b_t, \quad \sum_{t=1}^T \alpha_t = 1, \quad \alpha_t \ge 0$$
    \item \textbf{Смесь алгоритмов} (\textit{mixture of experts}) с функциями компетентности (\textit{gating function}) $g_t: X \to \mathbb{R}$
    $$F(b_1, \dots, b_T, x) = \sum_{t=1}^T g_t(x) b_t(x)$$
\end{itemize}
\subsection{Проблема разнообразия базовых алгоритмов}
Явное преимущество композиции алгоритмов - возможность использовать независимые модели при построении ансамбля. Однако на практике  часто возникает ситуация, когда используется один и тот же алгоритм для создания ансамбля. Это, в свою очередь, приводит к тому, что модели в ансамбле не являются полностью независимыми.

Тем не менее, даже в случае использования одного и того же алгоритма, можно добиться некоторого разнообразия между моделями. Это может быть сделано за счет изменения параметров алгоритма, использования различных подмножеств данных для обучения (например, с помощью бэггинга, \textit{см. далее}) или применения различных техник предобработки данных. Кроме того, можно использовать различные способы инициализации или подходы к обучению, что также может привести к созданию моделей с различной производительностью.

\subsection{Методы стохастического ансамблирования} % Stochastic Ensemble Methods
Один из подходов к достижению этого разнообразия заключается в использовании методов рандомизации. Рандомизация позволяет генерировать различные обучающие подмножества данных, выбирать случайные подмножества признаков или изменять параметры моделей, что приводит к созданию разнообразного ансамбля и повышению его обобщающей способности. В данном разделе перечислены различные методы рандомизации, используемые для повышения разнообразия базовых моделей в ансамблях.

\ \

\textbf{Способы повышения разнообразия с помощью рандомизации:} 
\begin{itemize}
    \item \textit{bagging} (\textit{bootstrap aggregating}) – подвыборки обучающей выборки с возвращением: из исходной выборки размером \textit{N} образуется \textit{m} выборок, каждая из которых имеет тот же размер, что и исходный набор данных, но создаются они путем равномерного выбора элементов из исходного набора с возвратом. В каждую выборку попадает $1 - (1 - \frac{1}{\ell})^\ell$ уникальных объектов исходной выборки
    \item \textit{pasting} – случайные обучающие подвыборки 
    \item \textit{random subspaces} – случайные подмножества признаков 
    \item \textit{random patches} – случ. подмн-ва объектов и признаков 
    \item \textit{cross-validated committees} – выборка разбивается на $k$ блоков ($k$-fold) и делается $k$ обучений без одного блока 
\end{itemize}
Пусть $\mu: (G, U) \mapsto b$ – метод обучения по подвыборке $U \subseteq X^\ell$, использующий только признаки из $G \subseteq F^n = \{f_1, \dots, f_n\}$ 

\ \ 

\textbf{Алгоритм стохастического ансамблирования:}
\\
\textbf{Вход:} 

обучающая выборка $X^\ell$; параметры: 

$T$, $\ell'$ – объём обучающих подвыборок, 

$n'$ – размерность признаковых подпространств, 

$\varepsilon_1$ – порог качества базовых алгоритмов на обучении, 

$\varepsilon_2$ – порог качества базовых алгоритмов на контроле.
\\ 
\textbf{Выход:} 

базовые алгоритмы $b_t$,  $t = 1, \dots, T$: 
\begin{itemize}
    \item $U_t$ = случайная подвыборка объёма $\ell'$ из $X^\ell$; 
    \item $G_t$ = случайное подмножество мощности $n'$ из $F^n$; 
    \item $b_t = \mu(G_t, U_t)$; % $b_t = \mu(G_t, U_t)$;
    \item \textbf{если} $Q(b_t, U_t) > \varepsilon_1$ \textbf{то} не включать $b_t$ в ансамбль; 
    \item \textbf{если} $Q(b_t, X^\ell \setminus U_t) > \varepsilon_2$ \textbf{то} не включать $b_t$ в ансамбль; 
\end{itemize}
\ \
\textbf{Применение агрегирующей функции:} 

В простейшем случае используется простое голосование:
$$b(x) = \frac{1}{T} \sum_{t=1}^T  b_t(x)$$

\subsection*{Преобразование простого голосования во взвешенное}
Мы ожидаем, что некоторые базовые алгоритмы могут быть более точными и надежными, чем другие. Поэтому перейдем от простого голосования к взвешенному, где каждому классификатору присваивается определенный вес, отражающий его вклад в итоговое предсказание, для повышения точности и гибкости ансамбля.
\begin{itemize}
    \item \textbf{Линейная модель} над готовыми признаками $b_t(x)$:
    $$b(x) = \sum_{t=1}^T \alpha_t b_t(x)$$
    \item \textbf{Обучение:} МНК для регрессии, LR для классификации: 
    $$Q(\alpha, X^\ell) = \sum_{i=1}^\ell \mathcal{L}(b(x_i), y_i) \to \min_\alpha$$
    \textbf{Регуляризация:} $\alpha_t \ge 0$ либо LASSO: $\sum_{t=1}^T |\alpha_t| \
    \lambda$. 
\end{itemize}
Другой подход при выборе весов модели, заключается в предположении, что наши модели являются \textit{независимыми}. Тогда вохможно применение байесовского классификатора:
\begin{itemize}
    \item \textbf{Наивный байесовский классификатор} предполагает независимость с.в. $b_t(x)$ и даёт аналитическое решение: 
    $$\alpha_t = \ln \frac{1 - p_t}{p_t}, \quad t = 1, \dots, T,$$
    $p_t$ – оценка вероятности ошибки базового алгоритма $b_t$.
\end{itemize}




\subsection*{Задачи}
\subsubsection*{Задача 1}
Напишите декомпозицию алгоритма задачи классификации на K классов в общем случае. Каким в этом случае будет решающее правило С?
\subsubsection*{Задача 2}
Напишите декомпозицию алгоритма задачи регрессии в общем случае. Используется ли в данном случае решающее правило?
\subsubsection*{Задача 3}
Оцените уникальность подвыборки в методе bootstrap aggregating, для избыточного набора объектов исходной выборки, т.е. при $\ell \to \infty$.



% Определяем тип документа
\documentclass[12pt]{article}

% Подключаем необходимые библиотеки
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[ russian, english]{babel}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{textcomp}
\usepackage{amsmath,amsfonts,amsthm,amssymb,amsbsy,amstext,amscd,amsxtra,multicol}
\usepackage{xparse}
\usepackage{ifthen}
\usepackage{bm} %%% bf in math mode
\usepackage{color}
\usepackage{graphicx}
\usetikzlibrary{automata,positioning,trees}
\usepackage{esint}
\usepackage[unicode]{hyperref}
\usepackage{multicol}
\definecolor{linkcolor}{HTML}{799B03} % цвет ссылок
\definecolor{urlcolor}{HTML}{799B03} % цвет гиперссылок
\hypersetup{pdfstartview=FitH,  linkcolor=linkcolor,urlcolor=urlcolor, colorlinks=true}

% Задаем параметры шрифта: размер, отступы..
\setlength{\topmargin}{-0.5in}
\setlength{\textheight}{9.1in}
\setlength{\oddsidemargin}{-0.4in}
\setlength{\evensidemargin}{-0.4in}
\setlength{\textwidth}{7in}
\setlength{\parindent}{0ex}
\setlength{\parskip}{1ex}


\begin{document}
\selectlanguage{russian}
\begin{center}
\textbf{\Large{
    Стекинг\\
    }}
    \end{center}
\\


\textbf{Стекинг в маинном оуении}


1. \textbf{Введение}  
С развитием машинного обучения и увеличением доступных данных разработчики ищут способы повысить точность моделей. Одной из популярных техник является \textbf{ансамблевое обучение} — метод, где несколько моделей объединяются для достижения лучшего результата.  

Стекинг (\textbf{Stacking}) — один из методов ансамблевого обучения. Это мощный инструмент, который помогает улучшить производительность за счет объединения предсказаний нескольких базовых моделей (например, линейных и нелинейных) с помощью метамодели.  

2. \textbf{Определение}  
Стекинг (\textbf{stacking}) — алгоритм ансамблирования, построение которого выглядит примерно так:

1)общая выборка разделяется на тренировочную и тестовую\\
2)тренировочная выборка делится на n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются (n-1)  фолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались\\
3)на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи


3. \textbf{Свойства стекинга} 

### Основные свойства:  \\
- \textbf{Гибкость:} базовые модели могут быть разными (деревья решений, нейронные сети, регрессии и т.д.). \\ 
- \textbf{Улучшение качества:} метамодель "учится" на ошибках базовых моделей, что позволяет улучшить общую точность.  \\
- \textbf{Устойчивость к переобучению:} при правильной настройке стекинг снижает риск переобучения за счет использования ансамбля моделей.  \\


4. \textbf{Пример использования}

### Задача: прогнозирование цены недвижимости  
Имеем датасет с характеристиками домов (площадь, количество комнат, район и т.д.) и их ценами. Требуется спрогнозировать цену на основе этих данных.  

### Шаги:  \\
1) Разделение данных:  \\
   - Тренировочные данные: 80\%  \\
   - Тестовые данные: 20\% \\
2) Обучение базовых моделей:\\
   - Модель 1: Линейная регрессия.  \\
   - Модель 2: Случайный лес.  \\
   - Модель 3: Градиентный бустинг.  \\
3) Формирование метаданных:\\ 
   - Собираем предсказания от каждой модели для тренировочного набора. Эти предсказания будут входными данными для метамодели.  \\
4) Обучение метамодели: \\
   - Используем простую линейную регрессию или логистическую регрессию как метамодель.  \\
5) Оценка:\\
   - Предсказываем цены на тестовом наборе с помощью метамодели.  \\

5. \textbf{Применение}\\
Стекинг можно и нужно использовать при решении реальных бизнес-задач, поскольку при умелом построении композиции алгоритмов он даже помогает бороться с типичными проблемами реальных данных. \\
Например при нехватки нужных данных, можем в качестве базовых алгоритмов использовать регрессию, а в качестве метаалгоритма использовать что-то основанное на деревьях, то ответ такого стекинга уже не будет совсем неадекватным даже при «повреждении» некоторых признаков.

6. ### \textbf{Преимущества, недостатки, зоны риска}

\textbf{Преимущества}:\\
- Гибкость. Стекинг позволяет комбинировать разные модели — как линейные, так и нелинейные. Это делает метод универсальным и применимым в различных задачах. Можно использовать несколько типов моделей, таких как решающие деревья, случайные леса, градиентный бустинг, нейронные сети и другие.\\
- Улучшение качества. В большинстве случаев стекинг позволяет достичь более высоких результатов по сравнению с использованием одной модели. Это происходит потому, что разные модели могут улавливать различные аспекты данных и компенсировать слабые стороны друг друга.\\
- Эффективное использование разнородных данных. Стекинг особенно полезен, когда разные модели хорошо работают с различными аспектами данных. \\
  
\textbf{Недостатки}:\\
- Сложность настройки. Выбор базовых моделей и метамодели требует тщательной настройки и кросс-валидации. Неправильно выбранная комбинация моделей может привести к ухудшению результата.\\
- Медленное обучение. Поскольку требуется обучить несколько базовых моделей, а затем еще и метамодель, процесс обучения может стать очень долгим и потребовать значительных вычислительных ресурсов.\\
- Сложность интерпретации. Многоуровневые ансамбли из нескольких моделей могут быть сложны для интерпретации.\\
- Риск переобучения. Если метамодель слишком сильно подстраивается под ошибки базовых моделей, есть риск переобучения.\\
\\
\\
\\
\\
\\
\textbf{Зоны риска}:\\
- Качество данных. Как и в других методах машинного обучения, стекинг сильно зависит от качества исходных данных. Если данные содержат много шума или выбросов, модели могут переобучиться, что приведет к снижению производительности.\\
- Сложность в реализации. Реализация стекинга требует аккуратного разделения данных на этапах обучения и тестирования, чтобы избежать утечек (leakage) между обучающими и тестовыми данными на разных уровнях. \\
- Переиспользование данных. Если стекинг не настроен правильно, например, если не используется кросс-валидация для получения метапризнаков, то возможно переобучение. Это может произойти из-за того, что одна и та же информация используется на нескольких этапах обучения, и модели начинают "запоминать" данные, а не обобщать закономерности.\\

### \textbf{Задачи}:

### \textbf{Задача 1}:

Вопрос: Представьте, что у вас есть три модели: решающее дерево, логистическая регрессия и случайный лес. Вы решили применить стекинг для улучшения качества предсказаний. Объясните, как будет выглядеть процесс применения стекинга на этих моделях, какие шаги необходимо выполнить, чтобы получить финальное предсказание.

Примерный ответ: \\
1. Обучение трех базовых моделей (решающее дерево, логистическая регрессия и случайный лес) на обучающей выборке.\\
2. Получение предсказаний от каждой из этих моделей на тестовой выборке. Эти предсказания становятся новыми признаками.\\
3. Обучение метамодели (например, логистической регрессии или другой модели) на этих новых признаках (предсказаниях базовых моделей).\\
4. Финальное предсказание делается на основе предсказаний метамодели.


### \textbf{Задача 2}: 

Вопрос: У вас есть набор данных для задачи бинарной классификации. Вы решили использовать стекинг с двумя базовыми моделями — решающим деревом и случайным лесом. Какой из следующих подходов к обучению метамодели будет корректным?

a) Обучить метамодель на тех же данных, что и базовые модели, чтобы улучшить результат.  \\
b) Обучить метамодель на кросс-валидационных предсказаниях базовых моделей на обучающей выборке.  \\
c) Обучить метамодель на случайных подвыборках данных, не связанных с предсказаниями базовых моделей.

Правильный ответ:  \\
b. Обучение метамодели на кросс-валидационных предсказаниях базовых моделей на обучающей выборке помогает избежать утечки данных и переобучения, так как метамодель не видит исходные данные, на которых обучались базовые модели.


### \textbf{Задача 3}:

Вопрос: Вам нужно реализовать стекинг вручную на Python (без использования готовых библиотек для стекинга). Опишите последовательность действий в виде простого псевдокода на основе следующего сценария:

- У вас есть обучающая выборка $X_{train}$ и метки $y_{train}$ \\
- Используйте две модели: логистическую регрессию и случайный лес \\
- Для метамодели используйте линейную регрессию.

Примерный ответ:\\
(Опишу примерный алгоритм)\\
1. Импорт нужных библмотек

2. Определение базовых моделей

3. Кросс-валидация для генерации метапризнаков

4. Обучение базовых моделей на каждом фолде
    
5. Получение предсказаний на валидационном фолде
    
6. Сохранение предсказаний как метапризнаки

7. Обучение метамодели на метапризнаках

8. Финальное предсказание на тестовых данных



\end{document}

